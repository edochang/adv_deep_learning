{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ba04a1",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b83609",
   "metadata": {},
   "source": [
    "homework grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fd0b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val grader loaded.\n",
      "\u001b[97m[INFO     00:00:699] \u001b[0m\u001b[97mModel non-batched inference grader\u001b[0m\n",
      "100%|███████████████████████████████████████████| 32/32 [00:10<00:00,  3.10it/s]\n",
      "\u001b[33m[WARNING  00:13:412] \u001b[0m\u001b[33m  - Test non-batched generate function                 [ 10 / 10  ]\u001b[0m\n",
      "\u001b[97m[INFO     00:13:412] \u001b[0m\u001b[97m --------------------------------------------------    [  10 /  10 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:13:412] \u001b[0m\u001b[97mModel batched inference grader\u001b[0m\n",
      "\u001b[33m[WARNING  00:19:877] \u001b[0m\u001b[33m  - Test batched generate function                     [ 15 / 15  ]\u001b[0m\n",
      "\u001b[97m[INFO     00:19:877] \u001b[0m\u001b[97m --------------------------------------------------    [  15 /  15 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:19:877] \u001b[0m\u001b[97mCoT Model Grader\u001b[0m\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:12<00:00,  3.04s/it]\n",
      "\u001b[33m[WARNING  00:32:922] \u001b[0m\u001b[33m  - Test the answer accuracy                           [ 25 / 25  ]\u001b[0m\n",
      "\u001b[97m[INFO     00:32:922] \u001b[0m\u001b[97m --------------------------------------------------    [  25 /  25 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:32:922] \u001b[0m\u001b[97mSFT Model Grader\u001b[0m\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:05<00:00,  1.43s/it]\n",
      "\u001b[33m[WARNING  00:40:061] \u001b[0m\u001b[33m  - Test the answer accuracy                           [ 25 / 25  ]\u001b[0m\n",
      "\u001b[97m[INFO     00:40:061] \u001b[0m\u001b[97m --------------------------------------------------    [  25 /  25 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:40:062] \u001b[0m\u001b[97mRFT Model Grader\u001b[0m\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:29<00:00,  7.29s/it]\n",
      "\u001b[33m[WARNING  01:10:507] \u001b[0m\u001b[33m  - Test the answer accuracy                           [ 30 / 25  ]\u001b[0m\n",
      "\u001b[97m[INFO     01:10:507] \u001b[0m\u001b[97m --------------------------------------------------    [  30 /  25 ]\u001b[0m\n",
      "\u001b[97m[INFO     01:10:507] \u001b[0m\u001b[97mTotal                                                    105 / 100\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m grader homework -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1202e477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_llm.py\n",
      "rft_model\n",
      "rft.py\n",
      "sft.py\n",
      "data.py\n",
      "__init__.py\n",
      "sft_model\n",
      "cot.py\n",
      "datagen.py\n",
      "rft_model/training_args.bin\n",
      "rft_model/special_tokens_map.json\n",
      "rft_model/chat_template.jinja\n",
      "rft_model/tokenizer.json\n",
      "rft_model/vocab.json\n",
      "rft_model/events.out.tfevents.1762487540.SD01-PC.5737.0\n",
      "rft_model/adapter_config.json\n",
      "rft_model/events.out.tfevents.1762487767.SD01-PC.5808.0\n",
      "rft_model/tokenizer_config.json\n",
      "rft_model/adapter_model.safetensors\n",
      "rft_model/README.md\n",
      "rft_model/merges.txt\n",
      "sft_model/training_args.bin\n",
      "sft_model/special_tokens_map.json\n",
      "sft_model/events.out.tfevents.1762486770.SD01-PC.5469.0\n",
      "sft_model/chat_template.jinja\n",
      "sft_model/tokenizer.json\n",
      "sft_model/vocab.json\n",
      "sft_model/events.out.tfevents.1762486981.SD01-PC.5637.0\n",
      "sft_model/adapter_config.json\n",
      "sft_model/tokenizer_config.json\n",
      "sft_model/events.out.tfevents.1762486943.SD01-PC.5564.0\n",
      "sft_model/adapter_model.safetensors\n",
      "sft_model/README.md\n",
      "sft_model/merges.txt\n",
      "Submission created: /home/edo/repo/adv_deep_learning/homework3/ecc567.zip 33.00 MB\n"
     ]
    }
   ],
   "source": [
    "# Delete the checkpoint directories to reduce submission size\n",
    "!rm -rf homework/sft_model/checkpoint-*\n",
    "!rm -rf homework/rft_model/checkpoint-*\n",
    "\n",
    "# bundle homework submission\n",
    "!python3 bundle.py homework ecc567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efc869c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val grader loaded.\n",
      "\u001b[97m[INFO     00:00:912] \u001b[0m\u001b[97mModel non-batched inference grader\u001b[0m\n",
      "100%|███████████████████████████████████████████| 32/32 [00:09<00:00,  3.29it/s]\n",
      "\u001b[97m[INFO     00:13:035] \u001b[0m\u001b[97m * Model non-batched inference grader                  [  10 /  10 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:13:035] \u001b[0m\u001b[97mModel batched inference grader\u001b[0m\n",
      "\u001b[97m[INFO     00:22:078] \u001b[0m\u001b[97m * Model batched inference grader                      [  15 /  15 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:22:079] \u001b[0m\u001b[97mCoT Model Grader\u001b[0m\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:14<00:00,  3.52s/it]\n",
      "\u001b[97m[INFO     00:37:174] \u001b[0m\u001b[97m * CoT Model Grader                                    [  25 /  25 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:37:175] \u001b[0m\u001b[97mSFT Model Grader\u001b[0m\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:05<00:00,  1.44s/it]\n",
      "\u001b[97m[INFO     00:44:322] \u001b[0m\u001b[97m * SFT Model Grader                                    [  25 /  25 ]\u001b[0m\n",
      "\u001b[97m[INFO     00:44:322] \u001b[0m\u001b[97mRFT Model Grader\u001b[0m\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:32<00:00,  8.13s/it]\n",
      "\u001b[97m[INFO     01:17:988] \u001b[0m\u001b[97m * RFT Model Grader                                    [  30 /  25 ]\u001b[0m\n",
      "\u001b[97m[INFO     01:17:988] \u001b[0m\u001b[97mTotal                                                    105 / 100\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# test submission bundle\n",
    "!python3 -m grader ecc567.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb7a0e",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1\n",
    "\n",
    "Note: use `!` magic command to execute a shell command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f38db751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'homework.base_llm' found in sys.modules after import of package 'homework', but prior to execution of 'homework.base_llm'; this may result in unpredictable behaviour\n",
      "2025-11-03 21:34:39.822951: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-03 21:34:40.477298: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-03 21:34:42.636321: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "BaseLLM __initi__: Loaded model on device: cuda\n",
      "testing generate function\n",
      "input The cat went up\n",
      "output  the stairs and then down again.\n",
      "\n",
      "What is wrong with this sentence?\n",
      "testing generate function\n",
      "input The dog went down\n",
      "output  the stairs and into the basement.\n",
      "\n",
      "Both sentences are grammatically correct, but they have slightly different meanings. The first sentence implies that the dog is going upstairs (downstairs) to the basement, while the second sentence suggests that the dog is going downstairs (upstairs).\n",
      "\n",
      "In general, if you're describing a movement from one location to another, use \"down\" for a downward motion, and \"up\" for an upward motion. If you're describing a movement from one place to another in relation to a specific direction or level, use \"down\" for a downward motion and \"up\" for an upward motion.\n",
      "[' the tree.\\n\\nBoth sentences are grammatically correct, but they have different meanings and uses. The first sentence implies that the cat climbed up a tree, while the second sentence suggests that the cat was already in the tree before climbing.\\n\\nTo clarify this difference, consider the following:\\n\\n1. If you\\'re describing an action that occurred after something else happened (like \"after I ate breakfast\"), then \"went\" is often used to indicate the time of day or the duration of the action. For example:\\n   - After I finished my homework, I went to bed.\\n   - She walked through the park, going for a run.\\n\\n2. If you\\'re describing an action that occurred at the same time as another event (', ' the stairs and into the basement.\\n\\nIn this sentence, \"down\" is an adverb modifying the verb \"went\". It indicates the direction of the action (going downstairs).\\n\\nNow let\\'s look at another example:\\n\\n* The cat sat on the mat.\\n* The cat was sitting on the mat.\\n\\nIn these sentences, \"sat\" is a verb that describes the state of the cat. It tells us what happened to the cat (it was sitting).\\n\\nSo, while both words can modify verbs, they have different functions in describing actions.']\n"
     ]
    }
   ],
   "source": [
    "!python -m homework.base_llm test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1d19f9",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3eba9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'homework.cot' found in sys.modules after import of package 'homework', but prior to execution of 'homework.cot'; this may result in unpredictable behaviour\n",
      "2025-11-03 21:35:40.333336: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-03 21:35:40.406705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-03 21:35:41.912757: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "BaseLLM __initi__: Loaded model on device: cuda\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:35<00:00,  8.81s/it]\n",
      "BaseLLM parse_answer: BAD answer:\n",
      "Conversion used: 1 meter/second/kilometer per hour\n",
      "Calculation: 4 * (1000 / 3600) = 4 * 0.66666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666\n",
      "benchmark_result.accuracy=0.54  benchmark_result.answer_rate=0.99\n"
     ]
    }
   ],
   "source": [
    "!python -m homework.cot test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a40eb",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b78fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'homework.sft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.sft'; this may result in unpredictable behaviour\n",
      "BaseLLM __initi__: Loaded model on device: cuda using model (HuggingFaceTB/SmolLM2-360M-Instruct) with float32\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "{'train_runtime': 119.4203, 'train_samples_per_second': 41.869, 'train_steps_per_second': 1.34, 'train_loss': 0.27209608554840087, 'epoch': 5.0}\n",
      "100%|█████████████████████████████████████████| 160/160 [01:59<00:00,  1.34it/s]\n",
      "BaseLLM __initi__: Loaded model on device: cuda using model (HuggingFaceTB/SmolLM2-360M-Instruct) with float32\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:08<00:00,  2.24s/it]\n",
      "benchmark_result.accuracy=0.66  benchmark_result.answer_rate=1.0\n"
     ]
    }
   ],
   "source": [
    "!python -m homework.sft train homework/sft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926d821",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be770e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate rft dataset with datagen\n",
    "\n",
    "# default parameters are oversample 10 and temperature 0.6\n",
    "!python -m homework.datagen --output_json data/rft.json\n",
    "\n",
    "#!python -m homework.datagen --output_json data/rft.json --oversample 10 --temperature 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6ae6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<frozen runpy>:128: RuntimeWarning: 'homework.rft' found in sys.modules after import of package 'homework', but prior to execution of 'homework.rft'; this may result in unpredictable behaviour\n",
      "BaseLLM __initi__: Loaded model on device: cuda using model (HuggingFaceTB/SmolLM2-360M-Instruct) with float32\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "  0%|                                                   | 0/140 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "{'train_runtime': 106.65, 'train_samples_per_second': 41.866, 'train_steps_per_second': 1.313, 'train_loss': 0.17551071984427316, 'epoch': 5.0}\n",
      "100%|█████████████████████████████████████████| 140/140 [01:46<00:00,  1.31it/s]\n",
      "BaseLLM __initi__: Loaded model on device: cuda using model (HuggingFaceTB/SmolLM2-360M-Instruct) with float32\n",
      "LLM Running on Micro Batches 32: 100%|████████████| 4/4 [00:23<00:00,  5.91s/it]\n",
      "benchmark_result.accuracy=0.87  benchmark_result.answer_rate=1.0\n"
     ]
    }
   ],
   "source": [
    "# Train RFT model\n",
    "!python -m homework.rft train homework/rft_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
